import tensorflow as tf
import tensorboard as tboard
import warnings
import pickle
import numpy as np
import matplotlib.pyplot as plt
import os
from tensorflow.python.framework import ops
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics.classification import accuracy_score


# ignore all of the tensorflow warnings
warnings.filterwarnings("ignore")
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
ops.reset_default_graph()


class LSTM_RNN(object):
    """
    Resources: Deep Learning with TensorFlow Second Edition
    
    
    The double underscore __ before variables/functions show that they are private names for the class and aren't
    meant to be referenced outside of the class. This is standard form.
    """
    def __init__(self, hidden_size, vocab_size, embedding_size, n_classes, max_len=None, learning_rate=0.01, rand_state=24):
        self.input = self.__input(max_len)
        self.seq_len = self.__seq_len()
        self.target = self.__target(n_classes)
        self.dropout_keep_prob = self.__dropout_keep_prob()
        self.word_embeddings = self.__word_embeddings(self.input, vocab_size, embedding_size, random_state)
        self.scores = self.__scores(self.word_embeddings, self.seq_len, hidden_size, n_classes, self.dropout_keep_prob,
                                    random_state)

        self.predict = self.__predict(self.scores)
        self.losses = self.__losses(self.scores, self.target)
        self.loss = self.__loss(self.losses)
        self.train_step = self.__train_step(learning_rate, self.loss)
        self.accuracy = self.__accuracy(self.predict, self.target)
        self.merged = tf.summary.merge_all()

    def __input(self, max_length):
        """
        :param max_len: max length on input tensor
        :return: input placeholder [batch_size, max_len]
        """
        return tf.placeholder(tf.int32, [None, max_length], name='input')

    def __seq_len(self):
        """
        allows dynamic sequence length
        :return:
        """
        return tf.placeholder(tf.int32, [None], name='lengths')

    def __target(self, n_classes):
        return tf.placeholder(tf.float32, [None, n_classes], name='target')

    def __dropout_keep_prob(self):
        return tf.placeholder(tf.float32, name='dropout_keep_prob')

    def __cell(self, hidden_size, dropout_keep_prob, seed=24):
        lstm_cell = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple=True)
        dropout_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, input_keep_prob=dropout_keep_prob,
                                                     output_keep_prob=dropout_keep_prob, seed=seed)
        return dropout_cell

    def __word_embeddings(self, x, vocab_size, embedding_size, seed=None):
        with tf.name_scope('word_embeddings'):
            embeddings = tf.get_variable("embeddings", shape=[vocab_size, embedding_size], dtype=tf.float32, initializer=None, regularizer=None, trainable=True, collections=None)
            embedded_words = tf.nn.embedding_lookup(embeddings, x)
        return embedded_words

